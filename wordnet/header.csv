Name,Header
GPRPy, GPRPy
GPRPy, Simplemost installation
GPRPy, Running the software
GPRPy, Running automatically generated scripts
GPRPy, In case of trouble
GPRPy, Uninstalling GPRPy
GPRPy, News
SRN-Deblur, Scale-recurrent Network for Deep Image Deblurring
SRN-Deblur, Our results on real data
SRN-Deblur, Results on the testing dataset
SRN-Deblur, More cases on real photos from previous papers:
SRN-Deblur, Prerequisites
SRN-Deblur, Installation
SRN-Deblur, Testing
SRN-Deblur, Evaluation
SRN-Deblur, Training
SRN-Deblur, Models
SRN-Deblur, How to choose
SRN-Deblur, Reference
SRN-Deblur, Contact
SRN-Deblur, Reference
sentinelsat, connect to the API
sentinelsat, download single scene by known product id
sentinelsat," search by polygon, time, and Hub query keywords"
sentinelsat, download all results from the search
sentinelsat, GeoJSON FeatureCollection containing footprints and metadata of the scenes
sentinelsat, GeoPandas GeoDataFrame with the metadata of the scenes and the footprints as geometries
sentinelsat," Get basic information about the product: its title, file size, MD5 sum, date, footprint and"
sentinelsat, its download url
sentinelsat, Get the product's full metadata available on the server
sentinelsat, same result as query above
RDN, Residual Dense Network for Image Super-Resolution
RDN, Contents
RDN, Introduction
RDN, Train
RDN, Prepare training data 
RDN, Begin to train
RDN, Test
RDN, Quick start
RDN, The whole test pipeline
RDN, Results
RDN, Citation
RDN, Acknowledgements
Fiona," Open a file for reading. We'll call this the ""source."""
Fiona," The file we'll write to, the ""destination"", must be initialized"
Fiona," with a coordinate system, a format driver name, and"
Fiona, a record schema.  We can get initial values from the open
Fiona, collection's ``meta`` property and then modify them as
Fiona, desired.
Fiona," Open an output file, using the same format driver and"
Fiona, coordinate reference system as the source. The ``meta``
Fiona, mapping fills in the keyword parameters of fiona.open().
Fiona, Process only the records intersecting a box.
Fiona, Get a point on the boundary of the record's
Fiona, geometry.
Fiona, Write the record out.
Fiona, The destination's contents are flushed to disk and the file is
Fiona, closed when its ``with`` block ends. This effectively
Fiona, executes ``dst.flush(); dst.close()``.
Fiona, Output:
Fiona," (u'coutwildrnp', 67)"
Fiona, Output:
Fiona," (0, u'coutwildrnp', 67)"
Fiona, Output:
Fiona, [u'bar']
Fiona,1
Fiona, Polygon
Fiona," OrderedDict([(u'PERIMETER', 1.22107), (u'FEATURE2', None), (u'NAME', u'Mount Naomi Wilderness'), (u'FEATURE1', u'Wilderness'), (u'URL', u'http://www.wilderness.net/index.cfm?fuse=NWPS&sec=wildView&wname=Mount%20Naomi'), (u'AGBUR', u'FS'), (u'AREA', 0.0179264), (u'STATE_FIPS', u'49'), (u'WILDRNP020', 332), (u'STATE', u'UT')])"
Fiona, Output:
Fiona," (0, u'coutwildrnp', 67)"
Fiona, Output:
Fiona,67
hmr, End-to-end Recovery of Human Shape and Pose
hmr, Requirements
hmr, Installation
hmr, Linux Setup with virtualenv
hmr, Install TensorFlow
hmr, Windows Setup with python 3 and Anaconda
hmr, if you need to get chumpy 
hmr, Demo
hmr, Webcam Demo (thanks @JulesDoe!)
hmr, Training code/data
hmr, Citation
hmr, Opensource contributions
apsg, APSG - python package for structural geologists
apsg, Installation
apsg, PyPI
apsg, Upgrading via pip
apsg, Installing APSG from the source distribution
apsg, Conda
apsg, Current release info
apsg, Installing apsg
apsg, Master version
apsg, Getting started
apsg, Documentation
apsg, Contributing
apsg, Donate
apsg, License
mplleaflet, mplleaflet
mplleaflet, Examples
mplleaflet, Basic usage
mplleaflet, IPython Notebook embedding
mplleaflet, Other examples
mplleaflet, Why mplleaflet?
mplleaflet, Installation
mplleaflet, Development
mplleaflet, Dependencies
pylops, Objective
pylops, Project structure
pylops, Getting started
pylops, From PyPi
pylops, From Conda-forge
pylops, From Docker
pylops, Contributing
pylops, 1. Fork and clone the repository
pylops, 2. Install PyLops in a new Conda environment
pylops, Documentation
pylops, History
pylops, Contributors
tensorflow-magenta, Getting Started
tensorflow-magenta, Installation
tensorflow-magenta, Automated Install (w/ Anaconda)
tensorflow-magenta, Manual Install (w/o Anaconda)
tensorflow-magenta, GPU Installation
tensorflow-magenta, Using Magenta
tensorflow-magenta, Playing a MIDI Instrument
tensorflow-magenta, Development Environment
tensorflow-magenta, PIP Release
facebookresearch-wav2letter, wav2letter++
facebookresearch-wav2letter, Building wav2letter++
facebookresearch-wav2letter, Full documentation
facebookresearch-wav2letter, Citation
facebookresearch-wav2letter, Join the wav2letter community
facebookresearch-wav2letter, License
omfvista, Grab a few elements of interest and plot em up!
omfvista, Grab the active plotting window
omfvista,  from the thresher tool
omfvista, Add our datasets
omfvista, Add the bounds axis
PRM, PyTorch Implementation
PRM, Prerequisites
PRM, Installation
PRM, Run demo
PRM, Citation 
GAN_stability, GAN stability
GAN_stability, Usage
GAN_stability, Notes
GAN_stability, Results
GAN_stability, celebA-HQ
GAN_stability, Imagenet
d3, D3: Data-Driven Documents
d3, Resources
d3, Installing
microsoft-malmo, Malm√∂ 
microsoft-malmo, Getting Started 
microsoft-malmo, MalmoEnv 
microsoft-malmo, Malmo as a native Python wheel 
microsoft-malmo, Problems: 
microsoft-malmo, Launching Minecraft with our Mod: 
microsoft-malmo, Launch an agent: 
microsoft-malmo, Running a Python agent: 
microsoft-malmo, Running a C++ agent: 
microsoft-malmo, Running a C agent: 
microsoft-malmo, Running a Java agent: 
microsoft-malmo, Running an Atari agent: (Linux only) 
microsoft-malmo, Citations 
microsoft-malmo, Code of Conduct 
da-faster-rcnn,  Domain Adaptive Faster R-CNN for Object Detection in the Wild 
da-faster-rcnn, Acknowledgment
da-faster-rcnn, Usage
da-faster-rcnn, Example
da-faster-rcnn, Other Implementation
facebookresearch-ResNeXt, ResNeXt: Aggregated Residual Transformations for Deep Neural Networks
facebookresearch-ResNeXt, Table of Contents
facebookresearch-ResNeXt, News
facebookresearch-ResNeXt, Introduction
facebookresearch-ResNeXt," Figure: Training curves on ImageNet-1K. (Left): ResNet/ResNeXt-50 with the same complexity (~4.1 billion FLOPs, ~25 million parameters); (Right): ResNet/ResNeXt-101 with the same complexity (~7.8 billion FLOPs, ~44 million parameters)."
facebookresearch-ResNeXt, Citation
facebookresearch-ResNeXt, Requirements and Dependencies
facebookresearch-ResNeXt, Training
facebookresearch-ResNeXt, 1x Complexity Configurations Reference Table
facebookresearch-ResNeXt, ImageNet Pretrained Models
facebookresearch-ResNeXt, Single-crop (224x224) validation error rate
facebookresearch-ResNeXt, Third-party re-implementations
vue-devtools, vue-devtools
vue-devtools, Installation
vue-devtools, Important Usage Notes
vue-devtools, Open component in editor
vue-devtools, Manual Installation
vue-devtools, Development
vue-devtools, Quick Start in chrome
vue-devtools, Testing as Firefox addon
vue-devtools, Common problems and how to fix
vue-devtools, License
tippecanoe," Linear features (world railroads), visible at all zoom levels"
tippecanoe," Discontinuous polygon features (buildings of Rhode Island), visible at all zoom levels"
tippecanoe," Continuous polygon features (states and provinces), visible at all zoom levels"
tippecanoe," Large point dataset (GPS bus locations), for visualization at all zoom levels"
tippecanoe," Clustered points (world cities), summing the clustered population, visible at all zoom levels"
tippecanoe, Show countries at low zoom levels but states at higher zoom levels
tippecanoe, Represent multiple sources (Illinois and Indiana counties) as separate layers
tippecanoe, Merge multiple sources (Illinois and Indiana counties) into the same layer
tippecanoe, Selectively remove and replace features (Census tracts) to update a tileset
tippecanoe, Output tileset
tippecanoe, Tileset description and attribution
tippecanoe, Input files and layer names
tippecanoe, Parallel processing of input
tippecanoe, Projection of input
tippecanoe, Zoom levels
tippecanoe, Tile resolution
tippecanoe, Filtering feature attributes
tippecanoe, Modifying feature attributes
tippecanoe, Filtering features by attributes
tippecanoe, Dropping a fixed fraction of features by zoom level
tippecanoe, Dropping a fraction of features to keep under tile size limits
tippecanoe, Dropping tightly overlapping features
tippecanoe, Line and polygon simplification
tippecanoe, Attempts to improve shared polygon boundaries
tippecanoe, Controlling clipping to tile boundaries
tippecanoe, Reordering features within each tile
tippecanoe, Adding calculated attributes
tippecanoe, Trying to correct bad source geometry
tippecanoe, Setting or disabling tile size limits
tippecanoe, Temporary storage
tippecanoe, Progress indicator
tippecanoe, Filters
tippecanoe, Examples:
tippecanoe, Output tileset
tippecanoe, Tileset description and attribution
tippecanoe, Layer filtering and naming
tippecanoe, Zoom levels
tippecanoe, Merging attributes from a CSV file
tippecanoe, Filtering features and feature attributes
tippecanoe, Setting or disabling tile size limits
tippecanoe, Options
tippecanoe, Options
tippecanoe, Example
lasio, lasio
lasio, Documentation
lasio, Quick start
lasio, License
DID-MDN, DID-MDN
DID-MDN, Density-aware Single Image De-raining using a Multi-stream Dense Network
DID-MDN, Prerequisites:
DID-MDN, Installation:
DID-MDN, Demo using pre-trained model
DID-MDN, Training (Density-aware Deraining network using GT label)
DID-MDN, Density-estimation Training (rain-density classifier)
DID-MDN, Testing
DID-MDN, Reproduce
DID-MDN, Dataset
DID-MDN, Acknowledgments
bootstrap, Table of contents
bootstrap, Quick start
bootstrap, Status
bootstrap, What's included
bootstrap, Bugs and feature requests
bootstrap, Documentation
bootstrap, Running documentation locally
bootstrap, Documentation for previous releases
bootstrap, Contributing
bootstrap, Community
bootstrap, Versioning
bootstrap, Creators
bootstrap, Thanks
bootstrap, Backers
bootstrap, Sponsors
bootstrap, Copyright and license
sequelize-sequelize, Sequelize
sequelize-sequelize, v5 Release
sequelize-sequelize, Table of Contents
sequelize-sequelize, Installation
sequelize-sequelize, Documentation
sequelize-sequelize, Responsible disclosure
sequelize-sequelize, Resources
sequelize-sequelize, Tools
sequelize-sequelize, Learning
sequelize-sequelize, Translations
DCPDN, DCPDN
DCPDN, Densely Connected Pyramid Dehazing Network (CVPR'2018)
DCPDN, Prerequisites:
DCPDN, Installation:
DCPDN, Demo using pre-trained model
DCPDN, Training (Fine-tuning)
DCPDN, Testing
DCPDN, Reproduce
DCPDN, Dataset
DCPDN, How to creat your own testing samples
DCPDN, Extension
DCPDN, Acknowledgments
react, [React](https://reactjs.org/) &middot; [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/facebook/react/blob/master/LICENSE) [![npm version](https://img.shields.io/npm/v/react.svg?style=flat)](https://www.npmjs.com/package/react) [![CircleCI Status](https://circleci.com/gh/facebook/react.svg?style=shield&circle-token=:circle-token)](https://circleci.com/gh/facebook/react) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://reactjs.org/docs/how-to-contribute.htmlyour-first-pull-request)
react, Installation
react, Documentation
react, Examples
react, Contributing
react, [Code of Conduct](https://code.fb.com/codeofconduct)
react, [Contributing Guide](https://reactjs.org/contributing/how-to-contribute.html)
react, Good First Issues
react, License
pose-residual-network-pytorch, Pose Residual Network
pose-residual-network-pytorch, Getting Started
pose-residual-network-pytorch, Prerequisites
pose-residual-network-pytorch, Installing
pose-residual-network-pytorch, Training
pose-residual-network-pytorch, Testing
pose-residual-network-pytorch, Results
pose-residual-network-pytorch, License
pose-residual-network-pytorch, Citation
gempy," <p align=""left""><img src=""docs/logos/gempy1.png"" width=""300""></p>"
gempy, What is it
gempy, Table of Contents
gempy, News
gempy, GemPy v2.0 beta release
gempy, What is new
gempy, Features
gempy, Sandbox
gempy, Remote Geomod: From GoogleEarth to 3-D Geology
gempy, Getting Started
gempy, Dependencies
gempy, Conflictive packages.
gempy, Installation
gempy, PyPi 
gempy, New in GemPy 2.0: Docker image
gempy, Pull Docker image from DockerHub
gempy, Manual
gempy, Windows installation guide (Jun 2019)
gempy, Documentation
gempy, References
iter-reason, Iterative Visual Reasoning Beyond Convolutions
iter-reason, Disclaimer
iter-reason, Prerequisites
iter-reason, Setup and Running
iter-reason, References
DeepGuidedFilter, Fast End-to-End Trainable Guided Filter
DeepGuidedFilter, Overview
DeepGuidedFilter, Try it on an image!
DeepGuidedFilter, Prepare Environment
DeepGuidedFilter, Ready to **GO** !
DeepGuidedFilter, Image Processing
DeepGuidedFilter, Semantic Segmentation with Deeplab-Resnet
DeepGuidedFilter, Saliency Detection with DSS
DeepGuidedFilter, Monocular Depth Estimation (TensorFlow version)
DeepGuidedFilter, Guided Filtering Layer
DeepGuidedFilter, Install Released Version
DeepGuidedFilter, Usage
DeepGuidedFilter, Training from scratch
DeepGuidedFilter, Prepare Training Environment
DeepGuidedFilter, Start to Train
DeepGuidedFilter, Citation
gitfolio, Gitfolio  [![Tweet](https://img.shields.io/twitter/url/https/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=personal%20website%20and%20a%20blog%20for%20every%20github%20user%20&url=https://github.com/imfunniee/gitfolio) ![GitHub release](https://img.shields.io/github/release/imfunniee/gitfolio.svg?style=popout-square) ![npm](https://img.shields.io/npm/dm/gitfolio.svg?style=popout-square) ![GitHub top language](https://img.shields.io/github/languages/top/imfunniee/gitfolio.svg?style=popout-square) ![GitHub last commit](https://img.shields.io/github/last-commit/imfunniee/gitfolio.svg?style=popout-square) ![GitHub](https://img.shields.io/github/license/imfunniee/gitfolio.svg?style=popout-square)
gitfolio, personal website + blog  for every github user
gitfolio, Getting Started
gitfolio, Let's Install
gitfolio, Let's Build
gitfolio, Let's Customize
gitfolio, Forks
gitfolio, Sorting Repos
gitfolio, Ordering Repos
gitfolio, Customize Themes
gitfolio, Customize background image
gitfolio, Let's Publish
gitfolio, Updating
gitfolio, Add a Blog
gitfolio, License
gitbucket-gitbucket, 4.31.2 - 7 Apr 2019
gitbucket-gitbucket, 4.31.1 - 17 Mar 2019
gitbucket-gitbucket, 4.31.0 - 17 Mar 2019
neural_renderer, Neural 3D Mesh Renderer (CVPR 2018)
neural_renderer, For PyTorch users
neural_renderer, Installation
neural_renderer, Running examples
neural_renderer, Example 1: Drawing an object from multiple viewpoints
neural_renderer, Example 2: Optimizing vertices
neural_renderer, Example 3: Optimizing textures
neural_renderer, Example 4: Finding camera parameters
neural_renderer, FAQ
neural_renderer, CPU implementation?
neural_renderer, Python3 support?
neural_renderer, Citation
facebookresearch-DensePose, DensePose: 
facebookresearch-DensePose, Installation
facebookresearch-DensePose, Inference-Training-Testing
facebookresearch-DensePose, Notebooks
facebookresearch-DensePose, Visualization of DensePose-COCO annotations:
facebookresearch-DensePose, DensePose-COCO in 3D:
facebookresearch-DensePose, Visualize DensePose-RCNN Results:
facebookresearch-DensePose, DensePose-RCNN Texture Transfer:
facebookresearch-DensePose, License
facebookresearch-DensePose," <a name=""CitingDensePose""></a>Citing DensePose"
node-qa-masker, node-qa-masker
node-qa-masker, Installation
node-qa-masker, Use Example
node-qa-masker, Landsat 8
node-qa-masker, MODIS Land Products
node-qa-masker, Looking for command line tool?
node-qa-masker, You are a GIS guy and want something GIS?
mapshaper, mapshaper
mapshaper, Introduction
mapshaper, Command line tool
mapshaper, Interactive web interface
mapshaper, Large file support
mapshaper, run the command line program
mapshaper, use the web UI locally
mapshaper, Building and testing
mapshaper, License
mapshaper, Acknowledgements
segyio, segyio 
segyio, Index 
segyio, Introduction 
segyio, Feature summary 
segyio, Getting started 
segyio, Quick start 
segyio, Get segyio 
segyio, Build segyio 
segyio, Developers 
segyio, Tutorial 
segyio, Basics 
segyio, Modes 
segyio, Mode examples 
segyio, Project goals 
segyio, SEG-Y Revisions 
segyio, Contributing 
segyio, xarray integration 
segyio, Reproducing the test data 
segyio, Examples 
segyio, Python 
segyio, MATLAB 
segyio, Common issues 
segyio, ImportError: libsegyio.so.1: cannot open shared object file
segyio, Possible solutions
segyio, RuntimeError: unable to find sorting
segyio, Possible solutions
segyio, History 
vid2vid, vid2vid
vid2vid, [Project](https://tcwang0509.github.io/vid2vid/) | [YouTube(short)](https://youtu.be/5zlcXTCpQqM) | [YouTube(full)](https://youtu.be/GrP_aOSXt5U) | [arXiv](https://arxiv.org/abs/1808.06601) | [Paper(full)](https://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf)
vid2vid, Video-to-Video Translation
vid2vid, Prerequisites
vid2vid, Getting Started
vid2vid, Installation
vid2vid, Testing 
vid2vid, Dataset
vid2vid, Training with Cityscapes dataset
vid2vid, Training with face datasets
vid2vid, Training with pose datasets
vid2vid, Training with your own dataset
vid2vid, More Training/Test Details
vid2vid, Citation
vid2vid, Acknowledgments
PVGeo, Demonstrations of *PVGeo*
PVGeo, Connections
PVGeo, Getting Started
PVGeo, Report Issues and Contribute
PVGeo, About the Authors [![Open Source](https://img.shields.io/badge/open--source-yes-brightgreen.svg)](https://opensource.com/resources/what-open-source)
PVGeo, Linking PVGeo to ParaView
CU-Net, 
CU-Net, **[Quantized Densely Connected U-Nets for Efficient Landmark Localization](https://arxiv.org/abs/1808.02194)**
CU-Net, **[CU-Net: Coupled U-Nets](https://arxiv.org/abs/1808.06521)**
CU-Net, Overview
CU-Net, Prerequisites
CU-Net, Training
CU-Net, Validation
CU-Net, Model Options
CU-Net, Project Page
CU-Net, Citation
cltk-cltk, The Classical Language Toolkit
cltk-cltk, About
cltk-cltk, Documentation
cltk-cltk, Installation
cltk-cltk, Tutorials
cltk-cltk, Contributing
cltk-cltk, Citation
cltk-cltk, Gratitude
cltk-cltk, License
ICNet, ICNet for Real-Time Semantic Segmentation on High-Resolution Images
ICNet, Introduction
ICNet, Usage
ICNet, Citation
ICNet, Questions
tetgen, get cell centroids
tetgen, extract cells below the 0 xy plane
tetgen, advanced plotting
tetgen, plot quality
geojson-vt, geojson-vt &mdash; GeoJSON Vector Tiles
geojson-vt, Demo
geojson-vt, Usage
geojson-vt, Options
geojson-vt, Install
DaSiamRPN, DaSiamRPN
DaSiamRPN, Introduction
DaSiamRPN, Prerequisites
DaSiamRPN, Pretrained model for SiamRPN
DaSiamRPN, Detailed steps to install the prerequisites
DaSiamRPN, Results
DaSiamRPN, Demo and Test on OTB2015
DaSiamRPN, License
DaSiamRPN, Citing DaSiamRPN
scikit-image-scikit-image, scikit-image: Image processing in Python
scikit-image-scikit-image, Installation from binaries
scikit-image-scikit-image, Installation from source
scikit-image-scikit-image, License (Modified BSD)
scikit-image-scikit-image, Citation
geonotebook, GeoNotebook [![CircleCI](https://circleci.com/gh/OpenGeoscience/geonotebook.svg?style=shield)](https://circleci.com/gh/OpenGeoscience/geonotebook) [![Gitter chat](https://badges.gitter.im/gitterHQ/gitter.png)](https://gitter.im/OpenGeoscience/geonotebook)
geonotebook, Screenshots
geonotebook, Installation
geonotebook, System Prerequisites
geonotebook, Clone the repo:
geonotebook," Make a virtualenv, install jupyter[notebook], install geonotebook"
geonotebook, Installing geonotebook for development
geonotebook, Run the notebook:
geonotebook, Configure the notebook:
geonotebook, Run the tests
geonotebook, Docker Container
geonotebook, Vagrant Machine
geonotebook, Tile Server
geonotebook, Use geoserver for tile serving
generator-arcgis-js-app, generator-arcgis-js-app
generator-arcgis-js-app, Getting Started
generator-arcgis-js-app, What is Yeoman?
generator-arcgis-js-app, Yeoman Generators
generator-arcgis-js-app, What is used?
generator-arcgis-js-app, Usage
generator-arcgis-js-app, Still a beta
generator-arcgis-js-app, Notes
generator-arcgis-js-app, Getting To Know Yeoman
generator-arcgis-js-app, License
tilelive-mapnik, tilelive-mapnik
tilelive-mapnik, Installation
tilelive-mapnik, Usage
map-vectorizer, An NYPL Labs project
map-vectorizer, Like OCR for maps
map-vectorizer, Example input
map-vectorizer, Example output
map-vectorizer, Extra feature detection
map-vectorizer, Dependencies
map-vectorizer, First run
map-vectorizer, Configuring
map-vectorizer, Required argument
map-vectorizer, Semi-optional arguments
map-vectorizer, Optional arguments
map-vectorizer, Customizing The Vectorizer to your own maps
map-vectorizer, Templates and other files
map-vectorizer, Other scripts
map-vectorizer, Acknowledgements
map-vectorizer, Change log
LapSRN, Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution (CVPR 2017)
LapSRN, Table of Contents
LapSRN, Introduction
LapSRN, Citation
LapSRN, Requirements and Dependencies
LapSRN, Installation
LapSRN, Start MATLAB
LapSRN, Test Pre-trained Models
LapSRN, Training LapSRN
LapSRN, Training MS-LapSRN
LapSRN, Third-Party Implementation
RESCAN, RESCAN: Recurrent Squeeze-and-Excitation Context Aggregation Net
RESCAN, Prerequisite
RESCAN, Project Structure
RESCAN, Best Practices
RESCAN, Default Dataset settings
RESCAN," Train, Test and Show"
RESCAN, Scripts
RESCAN, Cite
RESCAN, Recent Works
sg2im, sg2im
sg2im, Model
sg2im, Setup
sg2im, Pretrained Models
sg2im, Running Models
sg2im, (Optional): GraphViz
sg2im, Training new models
pymeshfix, Test of pymeshfix without VTK module
pymeshfix, Performs same mesh repair while leveraging VTK's plotting/mesh loading
pymeshfix, Read mesh from infile and output cleaned mesh to outfile
pymeshfix, Generate vertex and face arrays of cleaned mesh
pymeshfix, where v and f are numpy arrays or python lists
pymeshfix, Create object from vertex and face arrays
pymeshfix, Plot input
pymeshfix, Repair input mesh
pymeshfix, Access the repaired mesh with vtk
pymeshfix," Or, access the resulting arrays directly from the object"
pymeshfix, numpy np.float array
pymeshfix, numpy np.int32 array
pymeshfix, View the repaired mesh (requires vtkInterface)
pymeshfix, Save the mesh
pymeshfix, Create TMesh object
pymeshfix," tin.load_array(v, f)  or read arrays from memory"
pymeshfix, Attempt to join nearby components
pymeshfix, tin.join_closest_components()
pymeshfix, Fill holes
pymeshfix, Clean (removes self intersections)
pymeshfix, Check mesh for holes again
pymeshfix, Clean again if necessary...
pymeshfix, Output mesh
pymeshfix, or return numpy arrays
neural-motifs, neural-motifs
neural-motifs," Like this work, or scene understanding in general? You might be interested in checking out my brand new dataset VCR: Visual Commonsense Reasoning, at [visualcommonsense.com](https://visualcommonsense.com)!"
neural-motifs, Bibtex
neural-motifs, Setup
neural-motifs, help
Flow-Guided-Feature-Aggregation, Flow-Guided Feature Aggregation for Video Object Detection
Flow-Guided-Feature-Aggregation, Introduction
Flow-Guided-Feature-Aggregation, Disclaimer
Flow-Guided-Feature-Aggregation, License
Flow-Guided-Feature-Aggregation, Citing Flow-Guided Feature Aggregation
Flow-Guided-Feature-Aggregation, Main Results
Flow-Guided-Feature-Aggregation, Requirements: Software
Flow-Guided-Feature-Aggregation, Requirements: Hardware
Flow-Guided-Feature-Aggregation, Installation
Flow-Guided-Feature-Aggregation, Demo
Flow-Guided-Feature-Aggregation, Preparation for Training & Testing
Flow-Guided-Feature-Aggregation, Usage
Flow-Guided-Feature-Aggregation, Misc.
Flow-Guided-Feature-Aggregation, FAQ
facebookresearch-pyrobot, What can you do with PyRobot?
facebookresearch-pyrobot, Installation
facebookresearch-pyrobot, Installing both PyRobot and LoCoBot dependencies
facebookresearch-pyrobot, Installing just PyRobot
facebookresearch-pyrobot, Getting Started
facebookresearch-pyrobot, The Team
facebookresearch-pyrobot, Future features
facebookresearch-pyrobot, Citation
facebookresearch-pyrobot, License
Detectron, Detectron
Detectron, Introduction
Detectron, Update
Detectron, License
Detectron, Citing Detectron
Detectron, Model Zoo and Baselines
Detectron, Installation
Detectron, Quick Start: Using Detectron
Detectron, Getting Help
Detectron, References
DeepMVS, DeepMVS: Learning Multi-View Stereopsis
DeepMVS, Training
DeepMVS, Requirements
DeepMVS, Instructions
DeepMVS, Testing
DeepMVS, Requirements
DeepMVS, Instructions
DeepMVS, License
readgssi, readgssi
readgssi, requirements
readgssi, installation
readgssi, installing from source:
readgssi, usage
readgssi, basic functionality
readgssi, CSV output
readgssi, plotting
readgssi, example 1A
readgssi, example 1B
readgssi, example 1C: gain can be tricky depending on your colormap
readgssi, example 2A: no background removal
readgssi, example 2B: horizontal mean BGR algorithm applied
readgssi, contributors
readgssi, citation suggestion:
readgssi, known bugs:
readgssi, future
integral-human-pose, Integral Human Pose Regression
integral-human-pose, Introduction
integral-human-pose, Disclaimer
integral-human-pose, License
integral-human-pose, Citing Papers
integral-human-pose, Main Results
integral-human-pose, Environment
integral-human-pose, Installation
integral-human-pose, Preparation for Training & Testing
integral-human-pose, Extensions
gdal-docker, GDAL Docker Images
gdal-docker, Usage
pyro-ppl-pyro, Installing
pyro-ppl-pyro, Installing a stable Pyro release
pyro-ppl-pyro, Installing Pyro dev branch
pyro-ppl-pyro, Running Pyro from a Docker Container
pyro-ppl-pyro, Citation
3D-ResNets-PyTorch, 3D ResNets for Action Recognition
3D-ResNets-PyTorch, Update (2018/2/21)
3D-ResNets-PyTorch, Update (2018/01/16)
3D-ResNets-PyTorch, Update (2017/11/27)
3D-ResNets-PyTorch, Summary
3D-ResNets-PyTorch, Citation
3D-ResNets-PyTorch, Pre-trained models
3D-ResNets-PyTorch, Performance of the models on Kinetics
3D-ResNets-PyTorch, Requirements
3D-ResNets-PyTorch, Preparation
3D-ResNets-PyTorch, ActivityNet
3D-ResNets-PyTorch, Kinetics
3D-ResNets-PyTorch, UCF-101
3D-ResNets-PyTorch, HMDB-51
3D-ResNets-PyTorch, Running the code
striplog, Of course you don't need this one if you didn't install it yet.
striplog, Or whatever was the last version to build.
harismuneer-Ultimate-Facebook-Scraper, üî• Ultimate Facebook Scrapper 
harismuneer-Ultimate-Facebook-Scraper, Note
harismuneer-Ultimate-Facebook-Scraper, Sample
harismuneer-Ultimate-Facebook-Scraper, Screenshot
harismuneer-Ultimate-Facebook-Scraper, Usage
harismuneer-Ultimate-Facebook-Scraper, Installation
harismuneer-Ultimate-Facebook-Scraper, How to Run
harismuneer-Ultimate-Facebook-Scraper, Citation
harismuneer-Ultimate-Facebook-Scraper, Important Message
harismuneer-Ultimate-Facebook-Scraper, Authors
harismuneer-Ultimate-Facebook-Scraper, Haris Muneer
harismuneer-Ultimate-Facebook-Scraper, Hassaan Elahi
harismuneer-Ultimate-Facebook-Scraper, Contributions Welcome
harismuneer-Ultimate-Facebook-Scraper, Issues
harismuneer-Ultimate-Facebook-Scraper, License
nextflow-io-nextflow, Contents
GANimation, GANimation: Anatomically-aware Facial Animation from a Single Image
GANimation, [[Project]](http://www.albertpumarola.com/research/GANimation/index.html)[ [Paper]](https://arxiv.org/abs/1807.09251) 
GANimation, Prerequisites
GANimation, Data Preparation
GANimation, Run
GANimation, Citation
two-stream-dyntex-synth, Two-Stream Convolutional Networks for Dynamic Texture Synthesis
two-stream-dyntex-synth, Requirements
two-stream-dyntex-synth, Setup
two-stream-dyntex-synth, Dynamic texture synthesis
two-stream-dyntex-synth, Example usage
two-stream-dyntex-synth, Dynamics style transfer
two-stream-dyntex-synth, Example usage
two-stream-dyntex-synth, Temporally-endless dynamic texture synthesis
two-stream-dyntex-synth, Incremental dynamic texture synthesis
two-stream-dyntex-synth, Static texture synthesis
two-stream-dyntex-synth, Notes
two-stream-dyntex-synth, Citation
two-stream-dyntex-synth, License
ipyleaflet, ipyleaflet
ipyleaflet, Usage
ipyleaflet, Installation
ipyleaflet, Installation from sources
ipyleaflet, Documentation
ipyleaflet, License
ipyleaflet, Related projects
rasterio, Read raster bands directly to Numpy arrays.
rasterio, Combine arrays in place. Expecting that the sum will
rasterio," temporarily exceed the 8-bit integer range, initialize it as"
rasterio, a 64-bit float (the numpy default) array. Adding other
rasterio," arrays to it in-place converts those arrays ""up"" and"
rasterio, preserves the type of the total array.
rasterio, Write the product as a raster band to a new 8-bit file. For
rasterio," the new file's profile, we start with the meta attributes of"
rasterio," the source file, but then change the band count to 1, set the"
rasterio," dtype to uint8, and specify LZW compression."
rasterio, Printed:
rasterio," (791, 718)"
rasterio," {u'units': u'm', u'no_defs': True, u'ellps': u'WGS84', u'proj': u'utm', u'zone': 18}"
rasterio," Affine(300.0379266750948, 0.0, 101985.0,"
rasterio,"        0.0, -300.041782729805, 2826915.0)"
rasterio,3
rasterio," [1, 2, 3]"
rasterio, Printed:
rasterio," ((100, 200), (100, 200))"
puppeteer, Puppeteer
puppeteer, [API](https://github.com/GoogleChrome/puppeteer/blob/v1.18.0/docs/api.md) | [FAQ](faq) | [Contributing](https://github.com/GoogleChrome/puppeteer/blob/master/CONTRIBUTING.md) | [Troubleshooting](https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md)
puppeteer, What can I do?
puppeteer, Getting Started
puppeteer, Installation
puppeteer, puppeteer-core
puppeteer, Usage
puppeteer, Default runtime settings
puppeteer, Resources
puppeteer, Debugging tips
puppeteer, Basic verbose logging
puppeteer, Protocol traffic can be rather noisy. This example filters out all Network domain messages
puppeteer, Contributing to Puppeteer
puppeteer, FAQ
puppeteer, Q: Who maintains Puppeteer?
puppeteer, Q: What are Puppeteer‚Äôs goals and principles?
puppeteer, Q: Is Puppeteer replacing Selenium/WebDriver?
puppeteer, Q: Why doesn‚Äôt Puppeteer v.XXX work with Chromium v.YYY?
puppeteer, Q: Which Chromium version does Puppeteer use?
puppeteer, Q: What‚Äôs considered a ‚ÄúNavigation‚Äù?
puppeteer," Q: What‚Äôs the difference between a ‚Äútrusted"" and ""untrusted"" input event?"
puppeteer, Q: What features does Puppeteer not support?
puppeteer, Q: I am having trouble installing / running Puppeteer in my test environment. Where should I look for help?
puppeteer, Q: How do I try/test a prerelease version of Puppeteer?
puppeteer, Q: I have more questions! Where do I ask?
tensorflow, Installation
tensorflow, *Try your first TensorFlow program*
tensorflow, Contribution guidelines
tensorflow, Continuous build status
tensorflow, Official Builds
tensorflow, Community Supported Builds
tensorflow, For more information
tensorflow, License
vue, What's the difference between Patreon and OpenCollective?
vue, Introduction
vue, Browser Compatibility
vue, Ecosystem
vue, Documentation
vue, Questions
vue, Issues
vue, Changelog
vue, Stay In Touch
vue, Contribution
vue, License
reduxjs-react-redux, Installation
reduxjs-react-redux, React Native
reduxjs-react-redux, Documentation
reduxjs-react-redux, How Does It Work?
reduxjs-react-redux, License
pyansys, create a square area using keypoints
pyansys, Sample *.cdb
pyansys, Read ansys archive file
pyansys, Print raw data from cdb
pyansys, Create a vtk unstructured grid from the raw data and plot it
pyansys, write this as a vtk xml file 
pyansys, Load this from vtk
pyansys, Load the reader from pyansys
pyansys, Sample result file
pyansys, Create result object by loading the result file
pyansys, Beam natural frequencies
pyansys, Get the 1st bending mode shape.  Results are ordered based on the sorted 
pyansys, node numbering.  Note that results are zero indexed
pyansys, Plot the displacement of Mode 0 in the x direction
pyansys, Display node averaged stress in x direction for result 6
pyansys, Load the reader from pyansys
pyansys, load the full file
pyansys, returns upper triangle only
pyansys," make k, m full, symmetric matricies"
pyansys, condition the k matrix
pyansys," to avoid getting the ""Factor is exactly singular"" error"
pyansys, Solve
pyansys, System natural frequencies
kosmtik, Kosmtik
kosmtik, Lite
kosmtik, Screenshot
kosmtik, Install or Update
kosmtik, Usage
kosmtik, Configuration file
kosmtik, Local config
kosmtik, Example of a json file
kosmtik, Example of a js module
kosmtik, Custom renderers
kosmtik, Known plugins
pyGeoPressure, pyGeoPressure -->
pyGeoPressure, Features
pyGeoPressure, Getting Started
pyGeoPressure, Installation
pyGeoPressure, Example
pyGeoPressure, Pore Pressure Prediction using well log data
pyGeoPressure, Documentation
pyGeoPressure, Contribute
pyGeoPressure, Report Bugs
pyGeoPressure, Suggest Enhancements
pyGeoPressure, Submit Pull Requests
pyGeoPressure, Support
pyGeoPressure, License
DBNet, News!
DBNet, Contents
DBNet, Introduction
DBNet, Requirements
DBNet, Quick Start
DBNet, Training
DBNet, Evaluation    
DBNet, Prediction
DBNet, Baseline
DBNet, Contributors
DBNet, Citation
DBNet, License
Background-Matting, Background Matting: The World is Your Green Screen
Background-Matting, [**Project Page**](http://grail.cs.washington.edu/projects/background-matting/)
Background-Matting, Project members 
Background-Matting, License 
Background-Matting, Summary 
Background-Matting, **Updates** 
Background-Matting, Getting Started 
Background-Matting, Data
Background-Matting, Pre-trained model
Background-Matting, Pre-processing
Background-Matting, Background Matting
Background-Matting, Run the inference code on sample videos
Background-Matting, Data
Background-Matting, Pre-processing
Background-Matting, Background Matting
Background-Matting, Notes on capturing images
Background-Matting, Training code
Background-Matting, Dataset
Background-Matting, Notes
Background-Matting, Citation
CenterTrack, Tracking Objects as Points
CenterTrack, Abstract
CenterTrack, Features at a glance
CenterTrack, Pedestrian tracking on MOT17 test set
CenterTrack, 2D vehicle tracking on KITTI test set (with flip test)
CenterTrack, 3D tracking on nuScenes test set
CenterTrack, Installation
CenterTrack, Use CenterTrack
CenterTrack," or 'tracking,multi_pose' for pose tracking and 'tracking,ddd' for monocular 3d tracking"
CenterTrack, Benchmark Evaluation and Training
CenterTrack, License
COVIDNet, COVIDNet
COVIDNet, Table of Contents
COVIDNet, Installation
COVIDNet, Training
COVIDNet, Results 
COVIDNet, Results in COVIDx  dataset 
COVIDNet, Params (M) | MACs (G) |        Model        |
COVIDNet, Results in COVID-CT  dataset 
COVIDNet, Params (M) | MACs (G) |        Model        |
COVIDNet, 1) COVID-CT-Dataset
COVIDNet, 2) COVIDx  dataset 
COVIDNet, Steps to generate the COVIDx dataset
COVIDNet, Links
COVID-Net, COVID-Net Open Source Initiative
COVID-Net, Requirements
COVID-Net, COVIDx Dataset
COVID-Net, Steps to generate the dataset
COVID-Net, COVIDx data distribution
COVID-Net, Training and Evaluation
COVID-Net, Steps for training
COVID-Net, Steps for evaluation
COVID-Net, Steps for inference
COVID-Net, Steps for Training COVIDNet-Risk
COVID-Net, Results
COVID-Net, COVIDNet Small
COVID-Net, COVID-Net Large
COVID-Net, Pretrained Models
COVID-Net, Params (M) | MACs (G) |        Model        |
first-order-model, First Order Motion Model for Image Animation
first-order-model, Example animations
first-order-model, VoxCeleb Dataset
first-order-model, Fashion Dataset
first-order-model, MGIF Dataset
first-order-model, Installation
first-order-model, YAML configs
first-order-model, Pre-trained checkpoint
first-order-model, Animation Demo
first-order-model, Colab Demo 
first-order-model, Face-swap
first-order-model, Training
first-order-model, Evaluation on video reconstruction
first-order-model, Image animation
first-order-model, Datasets
first-order-model, Training on your own dataset
first-order-model, Additional notes
stable-baselines,*extra content
stable-baselines, Stable Baselines
stable-baselines, Main differences with OpenAI Baselines
stable-baselines, Documentation
stable-baselines, RL Baselines Zoo: A Collection of 100+ Trained RL Agents
stable-baselines, Installation
stable-baselines, Prerequisites
stable-baselines, Ubuntu
stable-baselines, Mac OS X
stable-baselines, Windows 10
stable-baselines, Install using pip
stable-baselines, Example
stable-baselines, Try it online with Colab Notebooks !
stable-baselines, Implemented Algorithms
stable-baselines, MuJoCo
stable-baselines, Testing the installation
stable-baselines, Projects Using Stable-Baselines
stable-baselines, Citing the Project
stable-baselines, Maintainers
stable-baselines, How To Contribute
stable-baselines, Acknowledgments
pytorch-a2c-ppo-acktr-gail, Please use hyper parameters from this readme. With other hyper parameters things might not work (it's RL after all)!
pytorch-a2c-ppo-acktr-gail, Supported (and tested) environments (via [OpenAI Gym](https://gym.openai.com))
pytorch-a2c-ppo-acktr-gail, Requirements
pytorch-a2c-ppo-acktr-gail, Contributions
pytorch-a2c-ppo-acktr-gail, Disclaimer
pytorch-a2c-ppo-acktr-gail, TODO
pytorch-a2c-ppo-acktr-gail, Visualization
pytorch-a2c-ppo-acktr-gail, A2C
pytorch-a2c-ppo-acktr-gail, PPO
pytorch-a2c-ppo-acktr-gail, ACKTR
pytorch-a2c-ppo-acktr-gail, MuJoCo
pytorch-a2c-ppo-acktr-gail, A2C
pytorch-a2c-ppo-acktr-gail, PPO
pytorch-a2c-ppo-acktr-gail, ACKTR
pytorch-a2c-ppo-acktr-gail, Enjoy
pytorch-a2c-ppo-acktr-gail, Atari
pytorch-a2c-ppo-acktr-gail, MuJoCo
pytorch-a2c-ppo-acktr-gail, A2C
pytorch-a2c-ppo-acktr-gail, PPO
pytorch-a2c-ppo-acktr-gail, ACKTR
coach, Coach
coach, Table of Contents
coach, Benchmarks
coach, Installation
coach, Tutorials and Documentation
coach, Running Coach
coach, Running Coach Dashboard (Visualization)
coach, Distributed Multi-Node Coach
coach, Batch Reinforcement Learning
coach, Supported Environments
coach, Supported Algorithms
coach, Value Optimization Agents
coach, Policy Optimization Agents
coach, General Agents
coach, Imitation Learning Agents
coach, Hierarchical Reinforcement Learning Agents
coach, Memory Types
coach, Exploration Techniques
coach, Citation
coach, Contact
coach, Disclaimer
chainerrl,*extra content
chainerrl, ChainerRL
chainerrl, Installation
chainerrl, Getting started
chainerrl, Algorithms
chainerrl, Visualization
chainerrl, Environments
chainerrl, Contributing
chainerrl, License
chainerrl, Citations
SPNet, Strip Pooling: Rethinking Spatial Pooling for Scene Parsing
SPNet, Strip Pooling
SPNet, Usage
SPNet, Better Results
SPNet, We believe designing more complicated strip pooling module also benefits to the model performance.
SPNet, Contact
SPNet, Citation
PyTorch-BayesianCNN, Bayesian CNN with Variational Inference
PyTorch-BayesianCNN, Filter weight distributions in a Bayesian Vs Frequentist approach
PyTorch-BayesianCNN, Fully Bayesian perspective of an entire CNN 
PyTorch-BayesianCNN, Make your custom Bayesian Network?
PyTorch-BayesianCNN, Notes: 
PyTorch-BayesianCNN, How to perform standard experiments?
PyTorch-BayesianCNN, Bayesian
PyTorch-BayesianCNN, Frequentist
PyTorch-BayesianCNN, Recording Mean and Variance:
PyTorch-BayesianCNN, DistPlots
PyTorch-BayesianCNN, LinePlots
PyTorch-BayesianCNN, Notes:
PyTorch-BayesianCNN, Directory Structure:
blitz-bayesian-deep-learning, Blitz - Bayesian Layers in Torch Zoo
blitz-bayesian-deep-learning, Index
blitz-bayesian-deep-learning, Install
blitz-bayesian-deep-learning, Documentation
blitz-bayesian-deep-learning, A simple example for regression
blitz-bayesian-deep-learning, Importing the necessary modules
blitz-bayesian-deep-learning, Loading and scaling data
blitz-bayesian-deep-learning, Creating our variational regressor class
blitz-bayesian-deep-learning, Defining a confidence interval evaluating function
blitz-bayesian-deep-learning, Creating our regressor and loading data
blitz-bayesian-deep-learning, Our main training and evaluating loop
blitz-bayesian-deep-learning, Bayesian Deep Learning in a Nutshell
blitz-bayesian-deep-learning," First of all, a deterministic NN layer linear transformation"
blitz-bayesian-deep-learning, The purpose of Bayesian Layers
blitz-bayesian-deep-learning, Weight sampling on Bayesian Layers
blitz-bayesian-deep-learning, It is possible to optimize our trainable weights
blitz-bayesian-deep-learning, It is also true that there is complexity cost function differentiable along its variables
blitz-bayesian-deep-learning, To get the whole cost function at the nth sample:
blitz-bayesian-deep-learning, Some notes and wrap up
blitz-bayesian-deep-learning, References:
blitz-bayesian-deep-learning, Special thanks to Intel Student Ambassador program
ExoTETHyS, ![ExoTETHyS logo](https://github.com/ucl-exoplanets/ExoTETHyS/blob/master/logo.png)
ExoTETHyS, Dependencies
ExoTETHyS, From Pypi  
ExoTETHyS, From GitHub  
ExoTETHyS, List of subpackages
ExoTETHyS, SAIL configuration file
ExoTETHyS," are ignored; keyword values preceded by \! are also ignored. Examples of configuration files can be found in the ""examples"" folder."
ExoTETHyS, TRIP configuration file
ExoTETHyS," are ignored; keyword values preceded by \! are also ignored. Examples of configuration files can be found in the ""examples"" folder."
ExoTETHyS, Description of examples
cosmoped, CosMOPED: a compressed Planck likelihood
cosmoped, Required packages
cosmoped, Usage
cosmoped, Compression vectors
cosmoped, Likelihood
cosmoped, Please cite
orcs, Introduction
orcs, Documentation
orcs, Examples
orcs, First basic examples
orcs, Bayesian fitting vs. classical fitting
orcs, Calibrating your data
orcs, Advanced fitting
orcs, Other Tools
orcs, Related Publications
orcs, 1. install [ORB](https://github.com/thomasorb/orb)
orcs, 2. add orcs module
DebrisDiskFM, DebrisDiskFM [![DOI](https://zenodo.org/badge/141328805.svg)](https://zenodo.org/badge/latestdoi/141328805)
DebrisDiskFM, 0. Installation
DebrisDiskFM, 1.1 MCFOST Parameter File Template
DebrisDiskFM, 1.2 MCFOST Parameter File Sample for a Specific Target
DebrisDiskFM, 1.3 Save parameter file
DebrisDiskFM, 2.1 Basic Baysian Statistics Knowledge
DebrisDiskFM, 2.2 Setting up the MCMC Framework for Debris Disk Modeling
DebrisDiskFM, 2.2.1 Prior Distribution
DebrisDiskFM, 2.2.2 Log-likelihood
DebrisDiskFM, 2.2.3 Poster Distribution
DebrisDiskFM, 2.3 Running MCFOST for the MCMC Framework
DebrisDiskFM, 3. Run MCMC
BTS, Behind The Spectrum fitting code
BTS, Dependencies 
BTS, Algorithm methodology 
BTS, User guide
BTS, The parameter file
BTS, The important three
BTS, Noise level parameters
BTS, Fits file parameters
BTS, Test run parameters
BTS, Flags
BTS, Future work
BTS, Acknowledgements 
BTS, Contact
covid-chestxray-dataset, COVID-19 image data collection
covid-chestxray-dataset, View current [images](images) and [metadata](metadata.csv)
covid-chestxray-dataset, Contribute
covid-chestxray-dataset, Background 
covid-chestxray-dataset, Motivation
covid-chestxray-dataset, Goal
covid-chestxray-dataset, Contact
covid-chestxray-dataset, Initial results
covid-chestxray-dataset, Citation
DeepCOVIDExplainer, DeepCOVIDExplainer: Explainable COVID-19 Diagnosis from Chest X-rays
DeepCOVIDExplainer, Methods
DeepCOVIDExplainer, Erratum 
DeepCOVIDExplainer, Datasets
DeepCOVIDExplainer, Data availability
DeepCOVIDExplainer, Availability of pretrained models
DeepCOVIDExplainer, A quick instructions
DeepCOVIDExplainer, Citation request
DeepCOVIDExplainer, Contributing
SuperGluePretrainedNetwork,*extra content
SuperGluePretrainedNetwork, Introduction
SuperGluePretrainedNetwork, Dependencies
SuperGluePretrainedNetwork, Contents
SuperGluePretrainedNetwork, Live Matching Demo Script (`demo_superglue.py`)
SuperGluePretrainedNetwork, Run the demo on a live webcam
SuperGluePretrainedNetwork, Run the demo on a directory of images
SuperGluePretrainedNetwork, Additional useful command line parameters
SuperGluePretrainedNetwork, Run Matching+Evaluation (`match_pairs.py`)
SuperGluePretrainedNetwork, Matches only mode
SuperGluePretrainedNetwork, Visualization mode
SuperGluePretrainedNetwork, Evaluation mode
SuperGluePretrainedNetwork, Running on sample outdoor pairs
SuperGluePretrainedNetwork, Recommended settings for indoor / outdoor
SuperGluePretrainedNetwork, Test set pair file format explained
SuperGluePretrainedNetwork, Reproducing the indoor evaluation on ScanNet
SuperGluePretrainedNetwork, Reproducing the outdoor evaluation on YFCC
SuperGluePretrainedNetwork, Reproducing outdoor evaluation on Phototourism
SuperGluePretrainedNetwork, Correcting EXIF rotation data in YFCC and Phototourism
SuperGluePretrainedNetwork, Outdoor training / validation scene splits of MegaDepth
SuperGluePretrainedNetwork, A note on reproducibility
SuperGluePretrainedNetwork, Creating high-quality PDF visualizations and faster visualization with --fast_viz
SuperGluePretrainedNetwork, BibTeX Citation
SuperGluePretrainedNetwork, Additional Notes
SuperGluePretrainedNetwork, Legal Disclaimer
SuperPointPretrainedNetwork,*extra content
SuperPointPretrainedNetwork, Introduction 
SuperPointPretrainedNetwork, Dependencies
SuperPointPretrainedNetwork, Running the Demo
SuperPointPretrainedNetwork, Run the demo on provided directory of images in CPU-mode:
SuperPointPretrainedNetwork, Run the demo on provided .mp4 file in GPU-mode:
SuperPointPretrainedNetwork, Run a live demo via webcam (id 1) in CPU-mode:
SuperPointPretrainedNetwork, Run the demo on a remote GPU (no display) on 640x480 images and write the output to `myoutput/`
SuperPointPretrainedNetwork, Additional useful command line parameters
SuperPointPretrainedNetwork, BibTeX Citation
SuperPointPretrainedNetwork, Additional Notes
SuperPointPretrainedNetwork, Legal Disclaimer
SuperGluePretrainedNetwork,*extra content
SuperGluePretrainedNetwork, Introduction
SuperGluePretrainedNetwork, Dependencies
SuperGluePretrainedNetwork, Contents
SuperGluePretrainedNetwork, Live Matching Demo Script (`demo_superglue.py`)
SuperGluePretrainedNetwork, Run the demo on a live webcam
SuperGluePretrainedNetwork, Run the demo on a directory of images
SuperGluePretrainedNetwork, Additional useful command line parameters
SuperGluePretrainedNetwork, Run Matching+Evaluation (`match_pairs.py`)
SuperGluePretrainedNetwork, Matches only mode
SuperGluePretrainedNetwork, Visualization mode
SuperGluePretrainedNetwork, Evaluation mode
SuperGluePretrainedNetwork, Running on sample outdoor pairs
SuperGluePretrainedNetwork, Recommended settings for indoor / outdoor
SuperGluePretrainedNetwork, Test set pair file format explained
SuperGluePretrainedNetwork, Reproducing the indoor evaluation on ScanNet
SuperGluePretrainedNetwork, Reproducing the outdoor evaluation on YFCC
SuperGluePretrainedNetwork, Reproducing outdoor evaluation on Phototourism
SuperGluePretrainedNetwork, Correcting EXIF rotation data in YFCC and Phototourism
SuperGluePretrainedNetwork, Outdoor training / validation scene splits of MegaDepth
SuperGluePretrainedNetwork, A note on reproducibility
SuperGluePretrainedNetwork, Creating high-quality PDF visualizations and faster visualization with --fast_viz
SuperGluePretrainedNetwork, BibTeX Citation
SuperGluePretrainedNetwork, Additional Notes
SuperGluePretrainedNetwork, Legal Disclaimer
pytorch-superpoint, torch-superpoint
pytorch-superpoint, Differences between our implementation and original paper
pytorch-superpoint, Results on HPatches
pytorch-superpoint, Requirements
pytorch-superpoint, Path setting
pytorch-superpoint, Dataset
pytorch-superpoint, will be automatically created
pytorch-superpoint, run the code
pytorch-superpoint, 1) Training MagicPoint on Synthetic Shapes
pytorch-superpoint, 2) Exporting detections on MS-COCO / kitti
pytorch-superpoint, General command:
pytorch-superpoint, export coco - do on training set 
pytorch-superpoint, export coco - do on validation set 
pytorch-superpoint, export kitti
pytorch-superpoint, export tum
pytorch-superpoint, 3) Training Superpoint on MS-COCO/ KITTI
pytorch-superpoint, General command
pytorch-superpoint, COCO
pytorch-superpoint, kitti
pytorch-superpoint, 4) Export/ Evaluate the metrics on HPatches
pytorch-superpoint, Export
pytorch-superpoint, evaluate
pytorch-superpoint, 5) Export/ Evaluate repeatability on SIFT (not tested)
pytorch-superpoint, Current best model
pytorch-superpoint, model from magicleap
pytorch-superpoint, Jupyter notebook 
pytorch-superpoint, Known problems
pytorch-superpoint, Work in progress
pytorch-superpoint, Credits
pytorch-superpoint, Posts
fiber,*extra content
fiber, Distributed Computing for AI Made Simple
fiber, Installation
fiber, Hello Fiber
fiber, Estimating Pi
fiber, Running on a Kubernetes cluster
fiber, Supported platforms
fiber, Documentation
fiber, Testing
fiber, Contributing
fiber, Versioning
fiber, License
fiber, Cite Fiber
fiber, Acknowledgments
CMC,*extra content
CMC, Contrastive Multiview Coding
CMC, Highlights
CMC, Updates
CMC, Installation
CMC, Training AlexNet/ResNets with CMC on ImageNet
CMC, Training Linear Classifier
CMC, Pretrained Models
CMC, Momentum Contrast and Instance Discrimination
CMC, Citation
CMC, Acknowledgements
CMC_with_Image_Mixture,*extra content
CMC_with_Image_Mixture, Contrastive Multiview Coding
CMC_with_Image_Mixture, Highlights
CMC_with_Image_Mixture, Updates
CMC_with_Image_Mixture, Installation
CMC_with_Image_Mixture, Training AlexNet/ResNets with CMC on ImageNet
CMC_with_Image_Mixture, Training Linear Classifier
CMC_with_Image_Mixture, Pretrained Models
CMC_with_Image_Mixture, Momentum Contrast and Instance Discrimination
CMC_with_Image_Mixture, Citation
CMC_with_Image_Mixture, Acknowledgements
TrianFlow, Towards Better Generalization: Joint Depth-Pose Learning without PoseNet
TrianFlow, Introduction
TrianFlow, Installation
TrianFlow, Run a demo
TrianFlow, Prepare training data:
TrianFlow, Training:
TrianFlow, Evaluation:
TrianFlow, Citation
TrianFlow, Related Projects
BBN, BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition
BBN, Main requirements
BBN, Pretrain models for iNaturalist
BBN, Usage
BBN, Data format
BBN, Citing this repository
BBN, Contacts
RPPPS,*extra content
